{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(window_name, canvas):\n",
    "    cv2.imshow(window_name, canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining colors\n",
    "white = (255,255,255)\n",
    "black = (0,0,0)\n",
    "green = (0,255,0)\n",
    "blue = (255, 0,0)\n",
    "red = (0,0,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary> ⭐⭐⭐⭐ OpenCV Image Convolutions (CLICK) </summary>\n",
    "\n",
    "\n",
    "<p>\n",
    "In reality, an (image) convolution is simply an element-wise multiplication of two matrices followed by a sum. <br>\n",
    "    1 . Take two matrices (which both have the same dimensions). <br>\n",
    "    2 . Multiply them, element-by-element (i.e., not the dot-product, just a simple multiplication). <br>\n",
    "    3 . Sum the elements together. <br> <br>\n",
    "    Think of an image as a big matrix and kernel or convolutional matrix as a tiny matrix that is used for blurring, sharpening, edge detection, and other image processing functions. This tiny kernel sits on top of the big image and slides from left-to-right and top-to-bottom, applying a mathematical operation (i.e., a convolution) at each (x, y)-coordinate of the original image. <br> <br>\n",
    "    Kernels can be an arbitrary size of M x N pixels, provided that both M and N are odd integers. <br>\n",
    "    1. Select an (x, y)-coordinate from the original image. <br>\n",
    "    2. Place the center of the kernel at this (x, y)-coordinate. <br>\n",
    "    3. Take the element-wise multiplication of the input image region and the kernel, then sum up the values of these multiplication operations into a single value. The sum of these multiplications is called the kernel output. <br>\n",
    "    4. Use the same (x, y)-coordinates from Step #1, but this time, store the kernel output in the same (x, y)-location as the output image. <br>\n",
    "</p>\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "\t# grab the spatial dimensions of the image, along with\n",
    "\t# the spatial dimensions of the kernel\n",
    "\t(iH, iW) = image.shape[:2]\n",
    "\t(kH, kW) = kernel.shape[:2]\n",
    "\t# allocate memory for the output image, taking care to\n",
    "\t# \"pad\" the borders of the input image so the spatial\n",
    "\t# size (i.e., width and height) are not reduced\n",
    "\tpad = (kW - 1) // 2\n",
    "\timage = cv2.copyMakeBorder(image, pad, pad, pad, pad,\n",
    "\t\tcv2.BORDER_REPLICATE)\n",
    "\toutput = np.zeros((iH, iW), dtype=\"float32\")\n",
    "\t# loop over the input image, \"sliding\" the kernel across\n",
    "\t# each (x, y)-coordinate from left-to-right and top to\n",
    "\t# bottom\n",
    "\tfor y in np.arange(pad, iH + pad):\n",
    "\t\tfor x in np.arange(pad, iW + pad):\n",
    "\t\t\t# extract the ROI of the image by extracting the\n",
    "\t\t\t# *center* region of the current (x, y)-coordinates\n",
    "\t\t\t# dimensions\n",
    "\t\t\troi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\t\t\t# perform the actual convolution by taking the\n",
    "\t\t\t# element-wise multiplicate between the ROI and\n",
    "\t\t\t# the kernel, then summing the matrix\n",
    "\t\t\tk = (roi * kernel).sum()\n",
    "\t\t\t# store the convolved value in the output (x,y)-\n",
    "\t\t\t# coordinate of the output image\n",
    "\t\t\toutput[y - pad, x - pad] = k\n",
    "    \n",
    "\t# rescale the output image to be in the range [0, 255]\n",
    "\toutput = rescale_intensity(output, in_range=(0, 255))\n",
    "\toutput = (output * 255).astype(\"uint8\")\n",
    "\t# return the output image\n",
    "\treturn output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
    "largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a sharpening filter\n",
    "sharpen = np.array((\n",
    "\t[0, -1, 0],\n",
    "\t[-1, 5, -1],\n",
    "\t[0, -1, 0]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Laplacian kernel used to detect edge-like\n",
    "# regions of an image\n",
    "laplacian = np.array((\n",
    "\t[0, 1, 0],\n",
    "\t[1, -4, 1],\n",
    "\t[0, 1, 0]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Sobel x-axis kernel\n",
    "sobelX = np.array((\n",
    "\t[-1, 0, 1],\n",
    "\t[-2, 0, 2],\n",
    "\t[-1, 0, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Sobel y-axis kernel\n",
    "sobelY = np.array((\n",
    "\t[-1, -2, -1],\n",
    "\t[0, 0, 0],\n",
    "\t[1, 2, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the kernel bank, a list of kernels we're going\n",
    "# to apply using both our custom `convole` function and\n",
    "# OpenCV's `filter2D` function\n",
    "kernelBank = (\n",
    "\t(\"small_blur\", smallBlur),\n",
    "\t(\"large_blur\", largeBlur),\n",
    "\t(\"sharpen\", sharpen),\n",
    "\t(\"laplacian\", laplacian),\n",
    "\t(\"sobel_x\", sobelX),\n",
    "\t(\"sobel_y\", sobelY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] applying small_blur kernel\n",
      "[INFO] applying large_blur kernel\n",
      "[INFO] applying sharpen kernel\n",
      "[INFO] applying laplacian kernel\n",
      "[INFO] applying sobel_x kernel\n",
      "[INFO] applying sobel_y kernel\n"
     ]
    }
   ],
   "source": [
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread(\"batman.jpg\", 1)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# loop over the kernels\n",
    "for (kernelName, kernel) in kernelBank:\n",
    "\t# apply the kernel to the grayscale image using both\n",
    "\t# our custom `convole` function and OpenCV's `filter2D`\n",
    "\t# function\n",
    "\tprint(\"[INFO] applying {} kernel\".format(kernelName))\n",
    "\tconvoleOutput = convolve(gray, kernel)\n",
    "\topencvOutput = cv2.filter2D(gray, -1, kernel)\n",
    "\t# show the output images\n",
    "\tcv2.imshow(\"original\", gray)\n",
    "\tcv2.imshow(\"{} - convole\".format(kernelName), convoleOutput)\n",
    "\tcv2.imshow(\"{} - opencv\".format(kernelName), opencvOutput)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Morphological Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python morphological_hats.py --image car.png\n",
    "\n",
    "# import the necessary packages\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "# load the image and convert it to grayscale\n",
    "image = cv2.imread(\"batman.jpg\",1)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# construct a rectangular kernel (13x5) and apply a blackhat\n",
    "# operation which enables us to find dark regions on a light\n",
    "# background\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
    "\n",
    "# similarly, a tophat (also called a \"whitehat\") operation will\n",
    "# enable us to find light regions on a dark background\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "\n",
    "# show the output images\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Blackhat\", blackhat)\n",
    "cv2.imshow(\"Tophat\", tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Smoothing and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python blurring.py\n",
    "\n",
    "# import the necessary packages\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# load the image, display it to our screen, and initialize a list of\n",
    "# kernel sizes (so we can evaluate the relationship between kernel\n",
    "# size and amount of blurring)\n",
    "image = cv2.imread(\"batman.jpg\",1)\n",
    "cv2.imshow(\"Original\", image)\n",
    "kernelSizes = [(3, 3), (9, 9), (15, 15)]\n",
    "\n",
    "# loop over the kernel sizes\n",
    "for (kX, kY) in kernelSizes:\n",
    "\t# apply an \"average\" blur to the image using the current kernel\n",
    "\t# size\n",
    "\tblurred = cv2.blur(image, (kX, kY))\n",
    "\tcv2.imshow(\"Average ({}, {})\".format(kX, kY), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "# close all windows to cleanup the screen\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "# loop over the kernel sizes again\n",
    "for (kX, kY) in kernelSizes:\n",
    "\t# apply a \"Gaussian\" blur to the image\n",
    "\tblurred = cv2.GaussianBlur(image, (kX, kY), 0)\n",
    "\tcv2.imshow(\"Gaussian ({}, {})\".format(kX, kY), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "# close all windows to cleanup the screen\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "# loop over the kernel sizes a final time\n",
    "for k in (3, 9, 15):\n",
    "\t# apply a \"median\" blur to the image\n",
    "\tblurred = cv2.medianBlur(image, k)\n",
    "\tcv2.imshow(\"Median {}\".format(k), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python bilateral.py\n",
    "\n",
    "# import the necessary packages\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", type=str, default=\"adrian.png\",\n",
    "\thelp=\"path to input image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the image, display it to our screen, and construct a list of\n",
    "# bilateral filtering parameters that we are going to explore\n",
    "image = cv2.imread(args[\"image\"])\n",
    "cv2.imshow(\"Original\", image)\n",
    "params = [(11, 21, 7), (11, 41, 21), (11, 61, 39)]\n",
    "\n",
    "# loop over the diameter, sigma color, and sigma space\n",
    "for (diameter, sigmaColor, sigmaSpace) in params:\n",
    "\t# apply bilateral filtering to the image using the current set of\n",
    "\t# parameters\n",
    "\tblurred = cv2.bilateralFilter(image, diameter, sigmaColor, sigmaSpace)\n",
    "\n",
    "\t# show the output image and associated parameters\n",
    "\ttitle = \"Blurred d={}, sc={}, ss={}\".format(\n",
    "\t\tdiameter, sigmaColor, sigmaSpace)\n",
    "\tcv2.imshow(title, blurred)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
