{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>AUTHOR- <u>NILUTPOL KASHYAP</u></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read, Write and Show Images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(\"lena.jpg\",0)    #0 for grayscale, 1 for color image, -1 for alpha channel\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"lena\",img)\n",
    "cv2.waitKey(0)         #0 to display until closed, or time in miliseconds\n",
    "cv2.destroyWindow('lena')\n",
    "#cv2.destoyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('lena_copy.jpg',img)    #creates a copy of lena.jpg as lena_copy.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2= cv2.imread(\"lena_copy.jpg\",-1)\n",
    "cv2.imshow(\"lena_copy\",img2)\n",
    "\n",
    "k= cv2.waitKey(0) & 0xFF      #0xFF is mask for 64-bit machines\n",
    "if k ==27:       #27 for ESC key\n",
    "    #cv2.destroyAllWindows()\n",
    "    cv2.destroyWindow(\"lena_copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read, Write and Show Videos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)       #0 for default camera, or video link\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)    #converts images to grayscale\n",
    "    #ret will save True if frame is available, frame will save the captured frame\n",
    "    cv2.imshow('video',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):      #To check if 'q' key is pressed \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n",
      "1920.0\n",
      "1080.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"video.mp4\")       #0 for default camera, or video link\n",
    "while(cap.isOpened()):    #Gives True only if file is opened, or else gives False\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    #cap.get() method Used to read properties\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))         #CAP_PROP_FRAME_WIDTH can also be written as 3\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))        #CAP_PROP_FRAME_HEIGHT can also be written as 4\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #ret will save True if frame is available, frame will save the captured frame\n",
    "    cv2.imshow('video',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):      #To check if 'q' key is pressed \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')     #fourcc is a 4 digit code to specify the video codex\n",
    "out = cv2.VideoWriter('newvideo.mp4',fourcc, 20.0,(1920,1080))     #VideoWriter class to output the video file from webcam\n",
    "                                                 #Arguments- (output_video_name, fourcc_code,no of frames, size of video)\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == True:      #Saves video only if ret is True\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('video',gray)\n",
    "        out.write(gray)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):      #To check if 'q' key is pressed \n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "out.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Draw geometric shapes on images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg',1)\n",
    "\n",
    "img = cv2.line(img, (0,0), (255,255), (0,255,0),5)      #Draws a line over image\n",
    "#Arguments - (image, start point, end point, color of line in BGR, thickness)\n",
    "\n",
    "img = cv2.arrowedLine(img, (0,0), (255,255), (0,255,0),5)        #Draws an arrowed line\n",
    "\n",
    "img = cv2.rectangle(img, (100,100), (300,300), (0,0,255), 5)      #Draws a rectangle over image\n",
    "#Thickness- -1 to fill rectangle, other +ve integers for thickness\n",
    "\n",
    "img = cv2.circle(img, (255,255), 100, (255,0,0), 5)\n",
    "#Arguments- (image, center, radius, color, thickness)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.putText(img, 'HELLO', (100,500), font, 3, (255,100,100), 10, cv2.LINE_AA)     #Write text over image\n",
    "#Arguments- (image, text, coordinates, font_type, font_size, font_color, thickness, line_type)\n",
    "\n",
    "cv2.imshow('lena',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using Numpy Zeroes Method</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros([1920,1080,3], dtype= np.uint8)      #[Height, Width,3]\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.putText(img, 'HELLO', (100,500), font, 3, (255,100,100), 10, cv2.LINE_AA)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting camera parameters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "1280.0\n",
      "720.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)       #0 for default camera, or video link\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))         #CAP_PROP_FRAME_WIDTH can also be written as 3\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))        #CAP_PROP_FRAME_HEIGHT can also be written as 4\n",
    "\n",
    "#cap.set() method used to set properties\n",
    "cap.set(3,1280)         #CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)        #CAP_PROP_FRAME_HEIGHT\n",
    "    \n",
    "#cap.get() method Used to read properties\n",
    "print(cap.get(3))         #CAP_PROP_FRAME_WIDTH can also be written as 3\n",
    "print(cap.get(4))        #CAP_PROP_FRAME_HEIGHT can also be written as 4\n",
    "\n",
    "while(cap.isOpened()):    #Gives True only if file is opened, or else gives False\n",
    "    ret,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #ret will save True if frame is available, frame will save the captured frame\n",
    "    cv2.imshow('video',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):      #To check if 'q' key is pressed \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Show Date and Time on Videos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)   \n",
    "cap.set(3,1280)         #CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)        #CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = \"Width: \"+ str(cap.get(3)) + 'Height: ' + str(cap.get(4))       #Text to print on the video frames\n",
    "    frame = cv2.putText(frame, text, (10,50), font, 1, (0,255,0),4,cv2.LINE_AA)\n",
    "    #Arguments- (image, text, coordinates, font_type, font_size, font_color, thickness, line_type)\n",
    "    \n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)   \n",
    "cap.set(3,1280)         #CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)        #CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    dtnow = str(datetime.datetime.now())       #Getting the current date & time to print on video frames\n",
    "    frame = cv2.putText(frame, dtnow, (10,50), font, 1, (0,255,0),4,cv2.LINE_AA)\n",
    "    #Arguments- (image, text, coordinates, font_type, font_size, font_color, thickness, line_type)\n",
    "    \n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Handle Mouse Events</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "print(events)       #To get all the mouse events methods in cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKING WITH LEFT & RIGHT MOUSE CLICKS\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:       #Left button click\n",
    "        print(x,',',y)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = 'Coord:' + str(x) + ',' + str(y)      #text for x & y coordinates of the click\n",
    "        cv2.putText(img, text, (x,y), font, .5, (255,0,0), 2)       #prints the x & y coordinates \n",
    "        cv2.imshow('image', img)\n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:      #Right button click\n",
    "        blue = img[y,x,0]       #0 for blue channel\n",
    "        green = img[y,x,1]      #1 for green channel\n",
    "        red = img[y,x,2]        #2 for red channel\n",
    "        print(blue,',',green,',',red)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        textBGR = 'BGR:' + str(blue) + ',' + str(green) + ',' + str(red)\n",
    "        cv2.putText(img, textBGR, (x,y), font, .5, (0,255,0), 2)    #Prints the BGR channel values\n",
    "        cv2.imshow('image', img)\n",
    "        \n",
    "#img = np.zeros((512,512,3), np.uint8)     #Creating a numpy array image of zeroes\n",
    "img = cv2.imread('lena.jpg',1)\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)     #Method used to call the click_event() callback function\n",
    "#Arguments- [window name, callback function]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:       #Left button click\n",
    "        cv2.circle(img, (x,y), 3, (0,255,255), -1)     #create a circle at mouse click point\n",
    "        #Arguments- (image, center, radius, color, thickness)\n",
    "        points.append((x,y))                 #appending the mouse click coordiantes to list\n",
    "        if len(points) >= 2:                 #check if point has atleast two  coordinates\n",
    "            cv2.line(img, points[-1],points[-2], (0,255,0), 3)     #join the last two coordinates stored in points list\n",
    "            #Arguments - (image, start point, end point, color of line in BGR, thickness)\n",
    "        cv2.imshow('image',img)\n",
    "        \n",
    "img = np.zeros((512,512,3), np.uint8)     #Creating a numpy array image of zeroes\n",
    "#img = cv2.imread('lena.jpg',1)\n",
    "cv2.imshow('image',img)\n",
    "points = []     #list to store mouse click coordinates\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)     #Method used to call the click_event() callback function\n",
    "#Arguments- [window name, callback function]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open  a new window of colour where mouse click event happened in the original image\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:       #Left button click\n",
    "        blue = img[y,x,0]       #0 for blue channel\n",
    "        green = img[y,x,1]      #1 for green channel\n",
    "        red = img[y,x,2]        #2 for red channel\n",
    "        cv2.circle(img, (x,y), 3,(0,0,255),-1)\n",
    "        mycolorimage = np.zeros((512,512,3), np.uint8)     #numpy zeros image \n",
    "        mycolorimage[:] = [blue,green,red]                 #assigning the color of BGR channel to numpy zeros image\n",
    "        cv2.imshow('color',mycolorimage)\n",
    "        \n",
    "#img = np.zeros((512,512,3), np.uint8)     #Creating a numpy array image of zeroes\n",
    "img = cv2.imread('lena.jpg',1)\n",
    "cv2.imshow('image',img)\n",
    "points = []     #list to store mouse click coordinates\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)     #Method used to call the click_event() callback function\n",
    "#Arguments- [window name, callback function]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Operations in Images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "786432\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "img= cv2.imread(\"lena.jpg\",1)\n",
    "print(img.shape)     #returns a tuple of rows, columns and channels\n",
    "print(img.size)      #returns total number of pixels\n",
    "print(img.dtype)     #returns image datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split operation\n",
    "b,g,r = cv2.split(img)    #splits the image into its channels\n",
    "cv2.imshow(\"b\",b)         #blu channel\n",
    "cv2.imshow(\"g\",g)         #green channel\n",
    "cv2.imshow(\"r\",r)         #red channel\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge operation\n",
    "img = cv2.merge((b,g,r))\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROI - Region of Interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding of two images\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "img2 = cv2.imread(\"robot.jpg\")\n",
    "\n",
    "#resize both the images to common size\n",
    "img = cv2.resize(img, (512,512))      #resize(image, (row,column))\n",
    "img2 = cv2.resize(img2, (512,512))\n",
    "\n",
    "add_img = cv2.add(img,img2)   #adding both images - overlapping\n",
    "\n",
    "cv2.imshow(\"output\",add_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding of two images with weights\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "img2 = cv2.imread(\"robot.jpg\")\n",
    "\n",
    "#resize both the images to common size\n",
    "img = cv2.resize(img, (512,512))      #resize(image, (row,column))\n",
    "img2 = cv2.resize(img2, (512,512))\n",
    "\n",
    "add_img = cv2.addWeighted(img, .5, img2, .5, 0)     #adds image with weighted values\n",
    "# dst = image1*alpha + image2*beta + gamma(scalar)\n",
    "# addWeighted(image1, aplha, image2, beta, gamma)\n",
    "\n",
    "cv2.imshow(\"output\",add_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bitwise Operations on Images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"bitimage.png\",3)\n",
    "img = cv2.resize(img,(500,250))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = np.zeros((250,500,3), np.uint8)\n",
    "img2 = cv2.rectangle(img2, (200,0), (300,100), (255,255,255),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise OR\n",
    "bitAnd = cv2.bitwise_and(img, img2)    #bitwise_and(image1, image2, dst=None, mask=None)\n",
    "cv2.imshow(\"bitAnd\",bitAnd)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise AND\n",
    "bitOr = cv2.bitwise_or(img, img2)    #bitwise_or(image1, image2, dst=None, mask=None)\n",
    "cv2.imshow(\"bitAnd\",bitOr)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise XOR\n",
    "bitXor = cv2.bitwise_xor(img, img2)    #bitwise_xor(image1, image2, dst=None, mask=None)\n",
    "cv2.imshow(\"bitAnd\",bitXor)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise NOT\n",
    "bitNot = cv2.bitwise_not(img)    #bitwise_not(image1, dst=None, mask=None)\n",
    "bitNot2 = cv2.bitwise_not(img2)\n",
    "cv2.imshow(\"bitAnd\",bitNot)\n",
    "cv2.imshow(\"bitAnd2\",bitNot2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trackbars in images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow('image')      #creating a named window\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "cv2.createTrackbar('Blue','image',0, 255, nothing)     #blue channel\n",
    "cv2.createTrackbar('Green','image',0, 255, nothing)    #green channel\n",
    "cv2.createTrackbar('Red','image',0, 255, nothing)      #red channel\n",
    "#createTrackbar('trackbar','named_window',lower_limit,upper_limit, callback_function)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    b = cv2.getTrackbarPos('Blue','image')    #getTrackbarPos('trackbar',image_window)\n",
    "    g = cv2.getTrackbarPos('Green','image')\n",
    "    r = cv2.getTrackbarPos('Red','image')\n",
    "    \n",
    "    img[:] = [b,g,r]             \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "7\n",
      "8\n",
      "11\n",
      "14\n",
      "21\n",
      "26\n",
      "31\n",
      "36\n",
      "47\n",
      "54\n",
      "65\n",
      "71\n",
      "77\n",
      "87\n",
      "96\n",
      "100\n",
      "103\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "120\n",
      "121\n",
      "122\n",
      "124\n",
      "126\n",
      "129\n",
      "131\n",
      "133\n",
      "135\n",
      "137\n",
      "139\n",
      "142\n",
      "144\n",
      "145\n",
      "147\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "1\n",
      "153\n",
      "149\n",
      "145\n",
      "140\n",
      "133\n",
      "128\n",
      "114\n",
      "104\n",
      "90\n",
      "81\n",
      "73\n",
      "68\n",
      "57\n",
      "50\n",
      "37\n",
      "28\n",
      "19\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "11\n",
      "14\n",
      "21\n",
      "27\n",
      "42\n",
      "52\n",
      "63\n",
      "77\n",
      "90\n",
      "105\n",
      "120\n",
      "135\n",
      "156\n",
      "174\n",
      "180\n",
      "186\n",
      "201\n",
      "204\n",
      "211\n",
      "216\n",
      "219\n",
      "224\n",
      "228\n",
      "230\n",
      "233\n",
      "235\n",
      "237\n",
      "240\n",
      "242\n",
      "245\n",
      "248\n",
      "251\n",
      "255\n",
      "2\n",
      "3\n",
      "6\n",
      "11\n",
      "16\n",
      "24\n",
      "30\n",
      "37\n",
      "53\n",
      "64\n",
      "74\n",
      "85\n",
      "89\n",
      "104\n",
      "116\n",
      "126\n",
      "137\n",
      "143\n",
      "158\n",
      "166\n",
      "181\n",
      "189\n",
      "193\n",
      "197\n",
      "203\n",
      "206\n",
      "210\n",
      "213\n",
      "216\n",
      "218\n",
      "220\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "235\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "242\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "255\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "10\n",
      "12\n",
      "13\n",
      "15\n",
      "20\n",
      "29\n",
      "40\n",
      "51\n",
      "58\n",
      "78\n",
      "92\n",
      "109\n",
      "123\n",
      "138\n",
      "158\n",
      "165\n",
      "174\n",
      "186\n",
      "189\n",
      "192\n",
      "197\n",
      "200\n",
      "206\n",
      "210\n",
      "213\n",
      "217\n",
      "219\n",
      "221\n",
      "223\n",
      "225\n",
      "227\n",
      "229\n",
      "234\n",
      "238\n",
      "239\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "248\n",
      "250\n",
      "252\n",
      "254\n",
      "255\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Adding switches in Trackbar\n",
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow('image')      #creating a named window\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "cv2.createTrackbar('Blue','image',0, 255, nothing)     #blue channel\n",
    "cv2.createTrackbar('Green','image',0, 255, nothing)    #green channel\n",
    "cv2.createTrackbar('Red','image',0, 255, nothing)      #red channel\n",
    "#createTrackbar('trrackbar','named_window',lower_limit,upper_limit, callback_function)\n",
    "\n",
    "switch = '0 : OFF\\n 1 : ON'\n",
    "cv2.createTrackbar(switch,'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    b = cv2.getTrackbarPos('Blue','image')    #getTrackbarPos('trackbar',image_window)\n",
    "    g = cv2.getTrackbarPos('Green','image')\n",
    "    r = cv2.getTrackbarPos('Red','image')\n",
    "    s = cv2.getTrackbarPos(switch, \"image\")\n",
    "    \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    elif s == 1:\n",
    "        img[:] = [b,g,r] \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Object Detection & Object Tracking using HSV(Hue, Saturation, Value)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing():\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('tracking')\n",
    "cv2.createTrackbar(\"L_HUE\",\"tracking\", 0, 255,nothing)\n",
    "cv2.createTrackbar(\"L_SAT\",\"tracking\", 0, 255,nothing)\n",
    "cv2.createTrackbar(\"L_VAL\",\"tracking\", 0, 255,nothing)\n",
    "cv2.createTrackbar(\"U_HUE\",\"tracking\", 255, 255,nothing)\n",
    "cv2.createTrackbar(\"U_SAT\",\"tracking\", 255, 255,nothing)\n",
    "cv2.createTrackbar(\"U_VAL\",\"tracking\", 255, 255,nothing)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    frame = cv2.imread('gems.jpg')\n",
    "    hsv= cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"L_HUE\",'tracking')\n",
    "    l_s = cv2.getTrackbarPos(\"L_SAT\",'tracking')\n",
    "    l_v = cv2.getTrackbarPos(\"L_VAL\",'tracking')\n",
    "    u_h = cv2.getTrackbarPos(\"U_HUE\",'tracking')\n",
    "    u_s = cv2.getTrackbarPos(\"U_SAT\",'tracking')\n",
    "    u_v = cv2.getTrackbarPos(\"U_VAL\",'tracking')\n",
    "    \n",
    "    #Threshold values(upper & lower) for blue color\n",
    "    l_blue = np.array([l_h,l_s,l_v])        \n",
    "    u_blue = np.array([u_h,u_s,u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, l_blue, u_blue)\n",
    "    res = cv2.bitwise_and(frame, frame, mask= mask)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "    key=  cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
