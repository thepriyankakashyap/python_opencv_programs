{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(window_name, canvas):\n",
    "    cv2.imshow(window_name, canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining colors\n",
    "white = (255,255,255)\n",
    "black = (0,0,0)\n",
    "green = (0,255,0)\n",
    "blue = (255, 0,0)\n",
    "red = (0,0,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary> ⭐⭐⭐⭐ OpenCV Image Convolutions (CLICK) </summary>\n",
    "\n",
    "\n",
    "<p>\n",
    "In reality, an (image) convolution is simply an element-wise multiplication of two matrices followed by a sum. <br>\n",
    "    1 . Take two matrices (which both have the same dimensions). <br>\n",
    "    2 . Multiply them, element-by-element (i.e., not the dot-product, just a simple multiplication). <br>\n",
    "    3 . Sum the elements together. <br> <br>\n",
    "    Think of an image as a big matrix and kernel or convolutional matrix as a tiny matrix that is used for blurring, sharpening, edge detection, and other image processing functions. This tiny kernel sits on top of the big image and slides from left-to-right and top-to-bottom, applying a mathematical operation (i.e., a convolution) at each (x, y)-coordinate of the original image. <br> <br>\n",
    "    Kernels can be an arbitrary size of M x N pixels, provided that both M and N are odd integers. <br>\n",
    "    1. Select an (x, y)-coordinate from the original image. <br>\n",
    "    2. Place the center of the kernel at this (x, y)-coordinate. <br>\n",
    "    3. Take the element-wise multiplication of the input image region and the kernel, then sum up the values of these multiplication operations into a single value. The sum of these multiplications is called the kernel output. <br>\n",
    "    4. Use the same (x, y)-coordinates from Step #1, but this time, store the kernel output in the same (x, y)-location as the output image. <br>\n",
    "</p>\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "    # grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "    \n",
    "    # allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    \n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "    # cv2.BORDER_REPLICATE: It replicates the last element. Suppose, if image contains \n",
    "    # letters “abcdefgh” then output will be “aaaaa|abcdefgh|hhhhh“. \n",
    "    \n",
    "    output = np.zeros((iH, iW), dtype=\"float32\")\n",
    "    \n",
    "    # loop over the input image, \"sliding\" the kernel across\n",
    "    # each (x, y)-coordinate from left-to-right and top to\n",
    "    # bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "            # perform the actual convolution by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel, then summing the matrix\n",
    "            k = (roi * kernel).sum()\n",
    "            # store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad] = k\n",
    "    \n",
    "    # rescale the output image to be in the range [0, 255]\n",
    "    output = rescale_intensity(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    "    # return the output image\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
    "largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a sharpening filter\n",
    "sharpen = np.array(([0, -1, 0], [-1, 5, -1], [0, -1, 0]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Laplacian kernel used to detect edge-like regions of an image\n",
    "laplacian = np.array(( [0, 1, 0], [1, -4, 1], [0, 1, 0]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Sobel x-axis kernel\n",
    "sobelX = np.array(( [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Sobel y-axis kernel\n",
    "sobelY = np.array(( [-1, -2, -1], [0, 0, 0], [1, 2, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the kernel bank, a list of kernels we're going\n",
    "# to apply using both our custom `convole` function and\n",
    "# OpenCV's `filter2D` function\n",
    "kernelBank = (\n",
    "    (\"small_blur\", smallBlur),\n",
    "    (\"large_blur\", largeBlur),\n",
    "    (\"sharpen\", sharpen),\n",
    "    (\"laplacian\", laplacian),\n",
    "    (\"sobel_x\", sobelX),\n",
    "    (\"sobel_y\", sobelY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] applying small_blur kernel\n",
      "[INFO] applying large_blur kernel\n",
      "[INFO] applying sharpen kernel\n",
      "[INFO] applying laplacian kernel\n",
      "[INFO] applying sobel_x kernel\n",
      "[INFO] applying sobel_y kernel\n"
     ]
    }
   ],
   "source": [
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread(\"batman.jpg\", 1)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# loop over the kernels\n",
    "for (kernelName, kernel) in kernelBank:\n",
    "    # apply the kernel to the grayscale image using both our custom `convole` function and OpenCV's `filter2D` function\n",
    "    \n",
    "    print(\"[INFO] applying {} kernel\".format(kernelName))\n",
    "    convoleOutput = convolve(gray, kernel)\n",
    "    opencvOutput = cv2.filter2D(gray, -1, kernel)\n",
    "    \n",
    "    # show the output images\n",
    "    cv2.imshow(\"original\", gray)\n",
    "    cv2.imshow(\"{} - convole\".format(kernelName), convoleOutput)\n",
    "    cv2.imshow(\"{} - opencv\".format(kernelName), opencvOutput)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Morphological Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary> ⭐⭐⭐⭐ OpenCV Morphological Operations (CLICK) </summary>\n",
    "\n",
    "\n",
    "<p>\n",
    "    Morphological operations are simple transformations applied to binary or grayscale images. \n",
    "    We can use morphological operations to increase the size of objects in images as well as decrease them. We can \n",
    "    also utilize morphological operations to close gaps between objects as well as open them. Like in image kernels, the structuring element slides from left-to-right and top-to-bottom for each pixel in the image. \n",
    "    \n",
    "    Morphological operations “probe” an image with a structuring element. Like in image kernels, the structuring element slides from left-to-right and top-to-bottom for each pixel in the image. \n",
    "</p>\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = cv2.imread(\"my_logo.jpg\", 1)\n",
    "gray = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "display(\"gray\", gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion\n",
    "Erosion works by defining a structuring element and then sliding this structuring element from left-to-right and top-to-bottom across the input image. A foreground pixel in the input image will be kept only if all pixels inside the structuring element are > 0. Otherwise, the pixels are set to 0 (i.e., background).\n",
    "\n",
    "The second argument to cv2.erode is the structuring element. If this value is None, then a 3×3 structuring element, identical to the 8-neighborhood structuring element we saw above will be used. Of course, you could supply your own custom structuring element here instead of None as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(gray.copy(), None, )\n",
    "display(\"eroded\", eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    eroded = cv2.erode(gray.copy(), None, iterations=i + 1)\n",
    "    display(\"eroded\", eroded)\n",
    "    \n",
    "# The for loop controls the number of times, or iterations, we are going to apply the erosion. As the number of \n",
    "# erosions increases, the foreground logo will start to “erode” and disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and convert it to grayscale\n",
    "image = cv2.imread(\"my_logo.jpg\",1)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# construct a rectangular kernel (13x5) and apply a blackhat\n",
    "# operation which enables us to find dark regions on a light\n",
    "# background\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
    "\n",
    "# similarly, a tophat (also called a \"whitehat\") operation will\n",
    "# enable us to find light regions on a dark background\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "\n",
    "# show the output images\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Blackhat\", blackhat)\n",
    "cv2.imshow(\"Tophat\", tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Smoothing and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python blurring.py\n",
    "\n",
    "# import the necessary packages\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# load the image, display it to our screen, and initialize a list of\n",
    "# kernel sizes (so we can evaluate the relationship between kernel\n",
    "# size and amount of blurring)\n",
    "image = cv2.imread(\"batman.jpg\",1)\n",
    "cv2.imshow(\"Original\", image)\n",
    "kernelSizes = [(3, 3), (9, 9), (15, 15)]\n",
    "\n",
    "# loop over the kernel sizes\n",
    "for (kX, kY) in kernelSizes:\n",
    "\t# apply an \"average\" blur to the image using the current kernel\n",
    "\t# size\n",
    "\tblurred = cv2.blur(image, (kX, kY))\n",
    "\tcv2.imshow(\"Average ({}, {})\".format(kX, kY), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "# close all windows to cleanup the screen\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "# loop over the kernel sizes again\n",
    "for (kX, kY) in kernelSizes:\n",
    "\t# apply a \"Gaussian\" blur to the image\n",
    "\tblurred = cv2.GaussianBlur(image, (kX, kY), 0)\n",
    "\tcv2.imshow(\"Gaussian ({}, {})\".format(kX, kY), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "# close all windows to cleanup the screen\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "# loop over the kernel sizes a final time\n",
    "for k in (3, 9, 15):\n",
    "\t# apply a \"median\" blur to the image\n",
    "\tblurred = cv2.medianBlur(image, k)\n",
    "\tcv2.imshow(\"Median {}\".format(k), blurred)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python bilateral.py\n",
    "\n",
    "# import the necessary packages\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", type=str, default=\"adrian.png\",\n",
    "\thelp=\"path to input image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the image, display it to our screen, and construct a list of\n",
    "# bilateral filtering parameters that we are going to explore\n",
    "image = cv2.imread(args[\"image\"])\n",
    "cv2.imshow(\"Original\", image)\n",
    "params = [(11, 21, 7), (11, 41, 21), (11, 61, 39)]\n",
    "\n",
    "# loop over the diameter, sigma color, and sigma space\n",
    "for (diameter, sigmaColor, sigmaSpace) in params:\n",
    "\t# apply bilateral filtering to the image using the current set of\n",
    "\t# parameters\n",
    "\tblurred = cv2.bilateralFilter(image, diameter, sigmaColor, sigmaSpace)\n",
    "\n",
    "\t# show the output image and associated parameters\n",
    "\ttitle = \"Blurred d={}, sc={}, ss={}\".format(\n",
    "\t\tdiameter, sigmaColor, sigmaSpace)\n",
    "\tcv2.imshow(title, blurred)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
